Jang C2N Practical Generative Noise Modeling for Real-World Denoising
基于学习的图像去噪方法已经局限于这样的情况，即给出了对齐良好的有噪声和干净的图像，或者从预定的噪声模型（例如，高斯）合成样本。尽管最近的生成噪声建模方法旨在模拟真实世界噪声的未知分布，但仍存在一些局限性。在实际场景中，噪声生成器应该学会在不使用成对的噪声和干净图像的情况下模拟一般和复杂的噪声分布。然而，由于现有的方法是基于对真实世界噪声的不切实际的假设构建的，它们往往会生成令人难以置信的模式，并且无法表达复杂的噪声图。因此，我们引入了一种干净到噪声的图像生成框架，即C2N，以在不使用任何配对示例的情况下模拟复杂的真实世界噪声。我们在C2N中相应地构建了具有真实世界噪声特性的每个分量的噪声生成器，以准确地表达宽范围的噪声。结合我们的C2N，传统的去噪CNN可以在具有挑战性的真实世界基准上被训练成在很大程度上优于现有的无监督方法。

Kim Continual Learning on Noisy Data Streams via Self-Purified Replay
在现实世界中不断学习必须克服许多挑战，其中嘈杂的标签是一个常见且不可避免的问题。在这项工作中，我们首次提出了一个基于重放的连续学习框架，该框架同时解决了灾难性遗忘和噪声标签。我们的解决方案基于两个观察结果；（i） 即使有噪声标签，也可以通过自监督学习来减轻遗忘，并且（ii）重放缓冲区的纯度至关重要。基于这一点，我们提出了我们方法的两个关键组成部分：（i）一种名为self replay的自监督重放技术，它可以绕过由噪声标记数据产生的错误训练信号，以及（ii）自中心滤波器，它通过基于中心性的随机图集合来维护纯化的重放缓冲区。MNIST、CIFAR-10、CIFAR-100和WebVision在真实世界噪声下的实证结果表明，我们的框架可以在噪声流数据中保持高度纯净的重放缓冲区，同时大大优于最先进的连续学习和噪声标签学习方法的组合。

Yu PlenOctrees for Real-Time Rendering of Neural Radiance Fields
我们介绍了一种使用PlenOctrees实时渲染神经辐射场（NeRF）的方法，PlenOctres是一种基于八叉树的3D表示，支持视图相关效果。我们的方法可以以超过150 FPS的速度渲染800x800张图像，这比传统的NeRF快3000多倍。我们在不牺牲质量的情况下这样做，同时保留了NeRF对具有任意几何体和视图相关效果的场景执行自由视点渲染的能力。实时性能是通过将NeRF预先制表为PlenOctree来实现的。为了保持与视图相关的效果，如镜面反射，我们通过闭合形式的球面基函数来分解外观。具体来说，我们证明了训练NeRF来预测辐射的球面谐波表示是可能的，去除了作为神经网络输入的观看方向。此外，我们还表明，可以直接优化PlenOctrees，以进一步最小化重建损失，与竞争方法相比，这将导致同等或更好的质量。此外，这个八叉树优化步骤可以用来减少训练时间，因为我们不再需要等待NeRF训练完全收敛。我们的实时神经渲染方法可能有可能实现新的应用，如6自由度工业和产品可视化，以及下一代AR/VR系统。PlenOctrees也适用于浏览器内渲染；请访问项目页面以获取交互式在线演示，以及视频和代码：https://alexyu.net/plenoctrees.

Chan Entropy Maximization and Meta Classification for Out-of-Distribution Detection in Semantic
用于图像语义分割的深度神经网络（DNN）通常被训练为对预定义的对象类的闭合集进行操作。这与DNN被设想部署到的“开放世界”设置形成了鲜明对比。从功能安全的角度来看，检测所谓的“分布外”（OoD）样本（即DNN语义空间之外的对象）的能力对自动驾驶等许多应用至关重要。OoD检测的一种自然基线方法是对像素方向的softmax熵进行阈值设置。我们提出了一个两步程序，大大改进了这种方法。首先，我们利用来自COCO数据集的样本作为OoD代理，并引入第二个训练目标来最大化这些样本的softmax熵。从预先训练的语义分割网络开始，我们在不同的分布内数据集上重新训练了许多DNN，并在完全不相交的OoD数据集上进行评估时，一致地观察到OoD检测性能的提高。其次，我们执行透明的后处理步骤，通过所谓的“元分类”来丢弃假阳性OoD样本。为此，我们将线性模型应用于从DNN的softmax概率导出的一组手工制作的度量。在我们的实验中，我们一致观察到OoD检测性能有明显的额外增益，当将最佳基线与我们的结果进行比较时，检测误差减少了52%。我们实现了这一改进，只略微牺牲了原始分割性能。因此，我们的方法有助于更安全的DNN和更可靠的整体系统性能。

Zhou Specificity-Preserving RGB-D Saliency Detection
RGB-D显著性检测由于其有效性和现在可以方便地捕捉深度线索的事实而引起了越来越多的关注。现有的工作通常侧重于通过各种融合策略学习共享表示，很少有方法明确考虑如何保持模态特定的特征。在本文中，从一个新的角度，我们提出了一种用于RGB-D显著性检测的特异性保留网络，该网络通过探索共享信息和模态特定属性（例如，特异性）来提高显著性检测性能。具体而言，采用两个模态特定网络和一个共享学习网络来生成个体显著性图和共享显著性图。提出了一种交叉增强集成模块（CIM）来融合共享学习网络中的跨模态特征，然后将其传播到下一层以集成跨级别信息。此外，我们提出了一个多模态特征聚合（MFA）模块，将来自每个单独解码器的模态特定特征集成到共享解码器中，该模块可以提供丰富的互补多模态信息，以提高显著性检测性能。此外，使用跳跃连接来组合编码器层和解码器层之间的分层特征。在六个基准数据集上的实验表明，我们的SP-Net优于其他最先进的方法。

Zhao 3DVG-Transformer Relation Modeling for Visual Grounding on Point Clouds
三维点云视觉基础是一项新兴的视觉和语言任务，有利于理解三维视觉世界的各种应用。通过将这项任务定义为基于检测的问题，最近的许多工作都集中在如何利用更强大的检测器和全面的语言特征上，但（1）如何对复杂关系进行建模以生成上下文感知的对象建议，以及（2）如何利用建议关系将真实的目标对象与类似的建议区分开来，还没有得到充分的研究。受众所周知的transformer架构的启发，我们提出了一种基于3D点云的关系感知视觉基础方法，称为3DVG transformer，以充分利用上下文线索进行关系增强的提案生成和跨模态提案消歧，这是由在对象建议生成阶段的新设计的坐标引导上下文聚合（CCA）模块和在跨模态特征融合阶段的多重注意力（MA）模块实现的。我们验证了我们的3DVG Transformer在基于两点云的视觉基础数据集（来自ReferIt3D的ScanRefer和Nr3D/Sr3D）上大大优于最先进的方法，尤其是在包含同一类别的多个对象的复杂场景中。

Vaksman Patch Craft Video Denoising by Deep Modeling and Patch Matching
自然图像的非局部自相似性已被广泛用于解决各种图像处理问题。当涉及到视频序列时，由于时间冗余，利用这种力量甚至更有益。在图像和视频去噪的背景下，许多面向经典的算法采用自相似性，将数据分割成重叠的补丁，收集相似的补丁组，并以某种方式将其处理在一起。随着卷积神经网络（CNN）的出现，基于补丁的框架已经被抛弃。大多数CNN去噪器对整个图像进行操作，仅通过使用大的接受场来隐含地利用非局部关系。这项工作提出了一种在视频去噪的背景下利用自相似性的新方法，同时仍然依赖于规则的卷积架构。我们引入了贴片工艺框架的概念——通过平铺匹配的贴片构建的与真实框架相似的人造框架。我们的算法用补丁工艺帧增强视频序列，并将其提供给CNN。我们展示了用所提出的方法获得的去噪性能的显著提高。

Cai AskConfirm Active Detail Enriching for Cross-Modal Retrieval With Partial Query
近年来，基于文本的图像检索取得了长足的进步。然而，现有方法的性能在现实生活中受到影响，因为用户可能提供图像的不完整描述，这通常导致结果充满了符合不完整描述的误报。在这项工作中，我们介绍了部分查询问题，并广泛分析了它对基于文本的图像检索的影响。以前的交互式方法通过被动地接收用户的反馈来迭代地补充不完整的查询来解决这个问题，这是耗时的，并且需要大量的用户努力。相反，我们提出了一种新颖的检索框架，该框架以询问和确认的方式进行交互过程，人工智能主动搜索当前查询中缺失的歧视性细节，用户只需要确认人工智能的提议。具体来说，我们提出了一种基于对象的交互，使交互式检索更用户友好，并提出了一个基于强化学习的策略来搜索有区别的对象。此外，由于难以获得人机对话数据，完全监督训练通常是不可行的，我们提出了一种弱监督训练策略，除了文本图像数据集之外，不需要人工注释的对话。实验表明，我们的框架显著提高了基于文本的图像检索的性能。代码位于https://github.com/CuthbertCai/Ask-Confirm.

Zhao Exploiting Explanations for Model Inversion Attacks
人工智能（AI）在从医疗保健到招聘的许多领域的成功部署需要负责任地使用，特别是在模型解释和隐私方面。可解释人工智能（XAI）提供了更多信息来帮助用户理解模型决策，但这些额外的知识暴露了隐私攻击的额外风险。因此，提供解释会损害隐私。我们研究了基于图像的模型反转攻击的这种风险，并确定了几种性能不断提高的攻击架构，以从模型解释中重建私人图像数据。我们已经开发了几种多模态转置CNN架构，它们实现了比仅使用目标模型预测高得多的反演性能。这些XAI感知反演模型旨在利用图像解释中的空间知识。为了了解哪些解释具有更高的隐私风险，我们分析了各种解释类型和因素如何影响反演性能。尽管一些模型没有提供解释，但我们通过注意力转移利用代理模型的解释，进一步证明了即使对于不可解释的目标模型，反演性能也有所提高。该方法首先从目标预测中推翻解释，然后重建目标图像。这些威胁凸显了解释的紧迫和重大隐私风险，并呼吁人们关注新的隐私保护技术，以平衡人工智能解释性和隐私的双重要求。

Ben-Cohen Semantic Diversity Learning for Zero-Shot Multi-Label Classification
训练用于识别与图像相关联的多个标签（包括识别看不见的标签）的神经网络模型是具有挑战性的，尤其是对于描绘许多语义不同标签的图像而言。尽管这项任务具有挑战性，但它是一项需要解决的重要任务，因为它代表了许多现实世界的情况，例如自然图像的图像检索。我们认为，像通常实践的那样，使用单个嵌入向量来表示图像不足以准确地对相关的可见和不可见标签进行排序。本研究介绍了一种用于多标签零样本学习的端到端模型训练，该训练支持图像和标签的语义多样性。我们建议使用具有使用定制损失函数训练的主嵌入向量的嵌入矩阵。此外，在训练过程中，我们建议在表现出更高语义多样性的损失函数图像样本中增加权重，以鼓励嵌入矩阵的多样性。大量实验表明，我们提出的方法提高了零样本模型在基于标签的图像检索中的质量，在几个常见数据集（NUS-Wide、COCO、Open Images）上实现了SoTA结果。

Qiu Describing and Localizing Multiple Changes With Transformers
现有的更改字幕研究主要集中在单个更改上。然而，检测和描述图像对中的多个变化部分对于增强对复杂场景的适应性至关重要。我们从三个方面解决了上述问题：（i）提出了一个基于模拟的多变化字幕数据集；（ii）我们将现有最先进的单次更改字幕方法与多次更改字幕进行比较；（iii）我们进一步提出了多变化字幕转换器（MCCFormer），其通过密集地关联图像对中的不同区域来识别变化区域，并动态地确定与句子中的单词相关的变化区域。所提出的方法在多变化字幕的四个传统变化字幕评估指标上获得了最高分数。此外，我们提出的方法可以为每个变化分离注意力图，并且在变化定位方面表现良好。此外，在现有的更改字幕基准CLEVR change上，所提出的框架大大优于以前最先进的方法（BLEU-4得分+6.1，CIDEr得分+9.7），表明其在更改字幕任务中的总体能力。项目页面上提供了代码和数据集。

Luo Score-Based Point Cloud Denoising
从扫描设备获取的点云经常受到噪声的干扰，这会影响表面重建和分析等下游任务。噪声点云的分布可以看作是一组无噪声样本p（x）与某个噪声模型n卷积后的分布，从而得到（p*n）（x），其模式是下面的清洁表面。为了对噪声点云进行去噪，我们建议通过梯度上升来增加每个点的对数似然性，即迭代更新每个点的位置。由于p*n在测试时是未知的，并且我们只需要分数（即对数概率函数的梯度）来执行梯度上升，因此我们提出了一种神经网络架构来估计p*n的分数，仅给定噪声点云作为输入。我们推导出用于训练网络的目标函数，并利用估计的分数开发去噪算法。实验表明，在各种噪声模型下，所提出的模型优于最先进的方法，并显示出应用于点云上采样等其他任务的潜力。

Garnot Panoptic Segmentation of Satellite Image Time Series With Convolutional Temporal
前所未有地获取多时相卫星图像为各种地球观测任务开辟了新的视角。其中，农业地块的像素精确全景分割具有重要的经济和环境影响。虽然研究人员已经在单个图像中探索了这个问题，但我们认为，通过图像的时间序列可以更好地解决作物表型的复杂时间模式。在本文中，我们提出了第一种端到端的单阶段卫星图像时间序列全景分割方法。该模块可以与我们新颖的图像序列编码网络相结合，该网络依赖于时间自注意来提取丰富且自适应的多尺度时空特征。我们还介绍了PASTIS，这是第一个具有全景注释的开放访问SITS数据集。我们展示了我们的编码器在语义分割方面相对于多种竞争网络架构的优势，并建立了SITS全景分割的第一个最先进技术。我们的实现和PASTIS数据集可在（发布后链接）上公开获取。

Wang Pyramid Vision Transformer A Versatile Backbone for Dense Prediction Without
尽管卷积神经网络（CNNs）在计算机视觉领域取得了巨大成功，但这项工作研究了一种更简单、无卷积的主干网络，可用于许多密集的预测任务。与最近提出的专门为图像分类设计的视觉转换器（ViT）不同，我们引入了金字塔视觉转换器（PVT），它克服了将转换器移植到各种密集预测任务的困难。与现有技术相比，PVT有几个优点。（1） 与通常产生低分辨率输出并导致高计算和内存成本的ViT不同，PVT不仅可以在图像的密集分区上进行训练以实现高输出分辨率，这对密集预测很重要，而且还使用渐进收缩金字塔来减少大特征图的计算。（2） PVT继承了CNN和Transformer的优势，使其成为各种视觉任务的统一主干，无需卷积，可以直接替代CNN主干。（3） 我们通过大量实验验证了PVT，表明它提高了许多下游任务的性能，包括对象检测、实例和语义分割。例如，在参数数量相当的情况下，PVT+RetinaNet在COCO数据集上实现了40.4个AP，超过ResNet50+Retina Net（36.3个AP）4.1个绝对AP。我们希望PVT可以作为像素级预测的替代和有用的支柱，并促进未来的研究。

Qiao Light Source Guided Single-Image Flare Removal From Unpaired Data
由于相机内部光线的意外反射和散射，因果拍摄的图像通常会出现光斑伪影。然而，由于光斑可能以各种形状、位置和颜色出现，因此从图像中完全检测和去除光斑是非常具有挑战性的。现有的方法依赖于光斑的预定义强度和几何先验，并且可能无法区分光源和光斑伪影之间的差异。我们观察到，图像中光源的条件在产生耀斑中起着重要作用。在本文中，我们提出了一个具有光源感知制导的深度框架，用于单图像光斑去除（SIFR）。特别地，我们首先分别检测光源区域和光斑区域，然后基于光源感知引导来去除光斑伪影。通过学习这两种区域之间的基本关系，我们的方法可以从图像中去除不同类型的光斑。此外，我们没有使用难以收集的成对训练数据，而是提出了第一个不成对的火炬去除数据集和新的循环一致性约束，以获得更多样的例子，并避免手动注释。大量实验表明，我们的方法在定性和定量上都优于基线。我们还展示了我们的模型可以应用于光斑效果操作（例如，添加或更改图像光斑）。

Wang RDI-Net Relational Dynamic Inference Networks
动态推理网络旨在提高计算效率，对给定的样本采用自适应执行路径。主流方法通常为每个卷积块分配一个路由器，并顺序地逐块执行决策，而不考虑动态推理过程中的关系。本文从路由器和样本两个方面对动态推理的关系进行了建模。我们设计了一种称为关系路由器的新型路由器，以对给定样本的路由器之间的关系进行建模。原则上，当前关系路由器通过图卷积聚合先前路由器的上下文特征，并将其路由器特征传播到后续路由器，从而以长距离的方式为当前块做出执行决策。此外，我们通过引入样本关系模块（SRM）来对样本之间的关系进行建模，鼓励相关样本沿着相关的执行路径前进。作为一个整体，我们将我们的方法称为关系动态推理网络（RDI-Net）。在CIFAR-10/100和ImageNet上进行的大量实验表明，RDI-Net实现了最先进的性能和计算成本的降低。我们的代码和模型将公开。

Huang ARAPReg An As-Rigid-As Possible Regularization Loss for Learning Deformable Shape
本文介绍了一种用于训练参数变形形状生成器的无监督损失。关键思想是在生成的形状中强制保持局部刚性。我们的方法建立在尽可能刚性（或ARAP）变形能量的局部近似上。我们展示了如何通过ARAP损失的Hessian谱分解来发展无监督损失。我们的损失通过一个稳健的范数很好地解耦了姿势和形状的变化。损失承认了简单的封闭形式表达。它易于训练，并且可以插入任何标准的一代模型，例如VAE和GAN。实验结果表明，在DFAUST、Animal和Bone等各种数据集中，我们的方法显著优于现有的形状生成方法。

Xie Online Refinement of Low-Level Feature Based Activation Map for Weakly
我们提出了一个用于弱监督对象定位（WSOL）的两阶段学习框架。虽然以前的大多数工作都依赖于基于高级特征的CAM（类激活映射），但本文提出使用基于低级特征的激活映射来定位对象。在第一阶段中，激活图生成器基于分类器中的低级特征图来生成激活图，使得以在线方式包括丰富的上下文对象信息。在第二阶段，我们使用评估器来评估由激活图生成器预测的激活图。在此基础上，我们进一步提出了加权熵损失、注意擦除和面积损失，以驱动激活图生成器大幅降低对象和背景之间激活的不确定性，并探索歧视性较小的区域。基于第一阶段中保存的低级别对象信息，第二阶段模型逐渐生成图像中对象的分离良好、完整且紧凑的激活图，该激活图可以很容易地进行阈值处理以进行精确定位。在CUB-2002-2011和ImageNet-1K数据集上进行的大量实验表明，我们的框架在很大程度上超过了以前的方法，这为WSOL奠定了新的技术水平。代码将很快提供。

Rivoir Long-Term Temporally Consistent Unpaired Video Translation From Simulated Surgical 3D
非配对视频翻译的研究主要集中在通过对相邻帧进行条件处理来实现短期时间一致性。然而，对于从模拟序列到照片真实感序列的转换，有关基础几何图形的可用信息为实现视图之间的全局一致性提供了潜力。我们提出了一种新的方法，该方法将不成对的图像转换与神经渲染相结合，将模拟的外科腹部场景转换为真实感外科腹部场景。通过引入全局可学习纹理和照明不变的视图一致性损失，我们的方法可以产生任意视图的一致翻译，从而实现长期一致的视频合成。我们设计并测试了我们的模型，以从微创手术腹部场景中生成视频序列。由于标记数据在该领域中通常是有限的，因此保存了来自模拟领域的地面实况信息的真实照片数据尤其相关。通过扩展现有的基于图像的方法来查看一致的视频，我们旨在影响模拟训练和评估环境在外科应用中的适用性。代码和数据：http://opencas.dkfz.de/video-sim2real.

Zhou TempNet Online Semantic Segmentation on Large-Scale Point Cloud Series
点云帧时间序列的在线语义分割是自动驾驶中的一项重要任务。现有的模型侧重于单帧分割，不能达到令人满意的分割精度，并且在帧之间提供不稳定的闪烁。在本文中，我们提出了一种用于大规模点云序列的轻量级语义分割框架，称为TempNet，通过结合一种新的帧聚合方案，可以提高现有语义分割模型的准确性和稳定性。为了计算成本高效，通过使用注意力池机制的时间特征聚合（TFA）网络，仅对关键帧的一小部分进行特征提取和聚合，并且这种增强的特征被传播到中间非关键帧。为了避免来自非关键帧的信息丢失，部分特征更新（PFU）网络被设计为如果快速评估到非关键帧上提取的局部特征与传播的特征之间的大视差，则部分特征更新网络利用在非关键帧中提取的局部特征对传播的特征进行部分更新。结果，可以为每个帧获得一致且信息丰富的特征。我们在五个最先进的（SOTA）点云分割模型上实现了TempNet，并在SemanticKITTI数据集上进行了广泛的实验。结果表明，TempNet在几乎没有额外计算成本的情况下以很大的优势优于SOTA的竞争对手。

